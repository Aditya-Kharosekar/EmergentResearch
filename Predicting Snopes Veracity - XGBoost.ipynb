{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Kharosekar\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import pre-trained Word Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_model = gensim.models.KeyedVectors.load_word2vec_format('../../Downloads/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07226562,  0.1171875 ,  0.16113281,  0.25976562, -0.14257812,\n",
       "       -0.08837891,  0.16992188, -0.00640869, -0.15917969,  0.03112793,\n",
       "       -0.11083984, -0.34179688, -0.1484375 ,  0.16796875, -0.07080078,\n",
       "        0.26171875,  0.07617188,  0.19628906, -0.00476074,  0.21972656,\n",
       "       -0.4140625 , -0.28320312,  0.11035156,  0.05517578, -0.1484375 ,\n",
       "       -0.08984375,  0.05737305,  0.09716797, -0.19921875, -0.25      ,\n",
       "        0.07617188,  0.05664062,  0.11279297, -0.11376953,  0.06982422,\n",
       "       -0.48828125, -0.25585938,  0.18457031,  0.18457031, -0.32226562,\n",
       "       -0.11865234, -0.03735352,  0.66015625,  0.3828125 ,  0.07910156,\n",
       "        0.3046875 , -0.09716797,  0.14160156, -0.06591797,  0.23632812,\n",
       "       -0.09277344,  0.01220703,  0.15527344,  0.25390625, -0.42773438,\n",
       "        0.11425781, -0.15039062, -0.45117188,  0.36328125, -0.09277344,\n",
       "       -0.22460938, -0.0559082 ,  0.1875    , -0.07275391,  0.18847656,\n",
       "       -0.36132812,  0.12207031, -0.07080078,  0.19335938,  0.19140625,\n",
       "        0.01855469,  0.29882812,  0.24414062,  0.27734375, -0.59765625,\n",
       "       -0.06591797, -0.03662109, -0.07275391, -0.18457031,  0.12451172,\n",
       "        0.25      ,  0.2578125 ,  0.09130859, -0.33789062,  0.20117188,\n",
       "        0.18164062,  0.06445312,  0.12988281, -0.10546875, -0.08886719,\n",
       "       -0.04199219,  0.03564453,  0.07421875, -0.21484375,  0.07958984,\n",
       "        0.37304688,  0.11328125,  0.38476562,  0.44726562,  0.06542969,\n",
       "       -0.07714844,  0.125     ,  0.01342773,  0.01501465, -0.19628906,\n",
       "        0.1796875 , -0.2734375 ,  0.0039978 ,  0.12353516,  0.39648438,\n",
       "       -0.16699219, -0.20214844,  0.3828125 , -0.04541016, -0.20117188,\n",
       "        0.49804688, -0.06396484, -0.34179688,  0.05444336, -0.16796875,\n",
       "        0.01208496, -0.20507812, -0.28320312,  0.13085938,  0.09277344,\n",
       "       -0.04736328, -0.15527344,  0.08056641, -0.0055542 ,  0.19335938,\n",
       "       -0.30078125,  0.02355957,  0.20410156,  0.05444336, -0.12890625,\n",
       "       -0.06030273, -0.03198242, -0.01928711,  0.28320312, -0.23925781,\n",
       "        0.29101562, -0.49414062,  0.07763672,  0.10400391,  0.01239014,\n",
       "       -0.09960938, -0.453125  ,  0.10839844,  0.18261719, -0.12597656,\n",
       "        0.30273438, -0.35546875, -0.08300781, -0.16113281, -0.0300293 ,\n",
       "       -0.296875  ,  0.2109375 ,  0.16308594, -0.09716797, -0.17675781,\n",
       "        0.14746094,  0.01068115, -0.05566406,  0.20703125, -0.07421875,\n",
       "       -0.34375   ,  0.13867188,  0.359375  ,  0.10058594, -0.12304688,\n",
       "       -0.24609375, -0.125     , -0.23046875,  0.16308594, -0.14453125,\n",
       "        0.328125  ,  0.09130859, -0.2109375 ,  0.32617188,  0.00714111,\n",
       "       -0.17382812,  0.03637695, -0.1484375 , -0.18554688,  0.17285156,\n",
       "        0.11181641, -0.12304688, -0.08251953,  0.11035156,  0.03735352,\n",
       "        0.11132812, -0.0625    ,  0.23828125,  0.18457031, -0.15429688,\n",
       "        0.07226562,  0.14941406, -0.21875   ,  0.16210938,  0.13574219,\n",
       "       -0.01928711,  0.0546875 , -0.12207031, -0.23242188,  0.01574707,\n",
       "       -0.17871094,  0.00088882, -0.30859375, -0.328125  ,  0.2421875 ,\n",
       "        0.03466797,  0.06054688, -0.10498047,  0.04492188, -0.28515625,\n",
       "        0.17871094,  0.02856445,  0.17871094, -0.09814453,  0.09277344,\n",
       "       -0.15332031, -0.27929688,  0.22851562, -0.26367188,  0.05908203,\n",
       "       -0.16503906,  0.08691406,  0.07958984,  0.14257812, -0.17480469,\n",
       "        0.2109375 , -0.53515625, -0.20410156, -0.08251953, -0.0625    ,\n",
       "        0.11621094,  0.06347656, -0.12695312,  0.14160156,  0.01867676,\n",
       "       -0.01611328,  0.12988281,  0.0222168 , -0.09375   , -0.55078125,\n",
       "       -0.23535156, -0.19433594,  0.18945312, -0.22363281,  0.02746582,\n",
       "       -0.01013184, -0.11523438,  0.17675781, -0.09521484,  0.07568359,\n",
       "       -0.28515625,  0.11474609, -0.03015137,  0.20703125, -0.22460938,\n",
       "        0.04394531, -0.12451172,  0.14257812, -0.16796875, -0.03027344,\n",
       "       -0.11376953,  0.19921875, -0.07128906,  0.18261719, -0.13769531,\n",
       "       -0.30859375, -0.10791016,  0.18457031,  0.25      ,  0.13085938,\n",
       "        0.00549316, -0.35742188, -0.13183594, -0.10986328,  0.40039062,\n",
       "       -0.36523438,  0.06445312, -0.11230469,  0.08447266,  0.26757812,\n",
       "       -0.10302734,  0.04418945, -0.00946045, -0.20996094, -0.09375   ,\n",
       "        0.14453125,  0.20019531, -0.125     ,  0.19628906,  0.02722168,\n",
       "       -0.17382812, -0.12109375, -0.33398438,  0.12353516,  0.15527344], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model['nasa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the list of words for which the google model has a vector\n",
    "google_vocab = google_model.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Find Word Embeddings\n",
    "\n",
    "### 2.1- Embeddings of Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>articleHeadline</th>\n",
       "      <th>predictedStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 Meijer Coupon - Snopes.com</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>Fake Meijer 100 back-to-school coupon goes vir...</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 Meijer Coupon - Hoax - Trendolizer</td>\n",
       "      <td>observing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 OFF Meijer Coupon Deals April 2017 HotDeal...</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>10 off 100 in Visa Gift Cards at Meijer - Freq...</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Meijer is offering 100 off Back to School coup...   \n",
       "1  Meijer is offering 100 off Back to School coup...   \n",
       "2  Meijer is offering 100 off Back to School coup...   \n",
       "3  Meijer is offering 100 off Back to School coup...   \n",
       "4  Meijer is offering 100 off Back to School coup...   \n",
       "\n",
       "                                     articleHeadline predictedStance  \n",
       "0                     100 Meijer Coupon - Snopes.com             for  \n",
       "1  Fake Meijer 100 back-to-school coupon goes vir...         against  \n",
       "2             100 Meijer Coupon - Hoax - Trendolizer       observing  \n",
       "3  100 OFF Meijer Coupon Deals April 2017 HotDeal...         against  \n",
       "4  10 off 100 in Visa Gift Cards at Meijer - Freq...             for  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_claims = pd.read_csv('Snopes_articles_with_predicted_stance.csv', index_col = 0)\n",
    "my_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes in a string. Tokenizes it, removes any punctuation in it\n",
    "#Does NOT change the case of the words though.\n",
    "def preprocessing(text):\n",
    "    if pd.isnull(text): #if article doesn't exist. Some claims have <10 articles.\n",
    "        return \"\"\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c,\"\")\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For a claim or an articleHeadline, this function will return the specified element of the word embedding for it\n",
    "def calc_vector(current_text, previous_text, previous_vector):\n",
    "    \n",
    "    #if article doesn't exist. Some claims have <10 articles\n",
    "    if pd.isnull(current_text):\n",
    "        return []\n",
    "    \n",
    "    #as each claim is repeated many times, this will be efficient for the 2nd through 10th time that we are finding the vector \n",
    "    #for a particular claim\n",
    "    if current_text==previous_text:\n",
    "        return previous_vector\n",
    "    \n",
    "    #if this is the first time we are finding the vector for this claim\n",
    "    words = preprocessing(current_text)\n",
    "    \n",
    "    text_vec = []\n",
    "    for word in words:\n",
    "        #checking if the word as written is in google model\n",
    "        if word in google_vocab:\n",
    "            text_vec =+ google_model[word]\n",
    "        \n",
    "        #checking if word in lowercase is in google model\n",
    "        elif word.lower() in google_vocab:\n",
    "            text_vec =+ google_model[word.lower()]\n",
    "        \n",
    "        #checking if word in uppercase is in google model\n",
    "        elif word.upper() in google_vocab:\n",
    "            text_vec =+ google_model[word.upper()]\n",
    "        \n",
    "        #checking if word in capital case (first character capitalized) is in model\n",
    "        elif word.capitalize() in google_vocab:\n",
    "            text_vec =+ google_model[word.capitalize()]\n",
    "        \n",
    "        #if not, just leave text_vec unchanged\n",
    "        else:\n",
    "            text_vec = text_vec\n",
    "    \n",
    "    #updating previous text and previous vector\n",
    "    previous_text = current_text\n",
    "    previous_vector = text_vec\n",
    "    \n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Information\n",
    "\n",
    "Column 0-299 - Word Embedding of claim\n",
    "\n",
    "Columns 300-599 - Word embedding of article headline\n",
    "\n",
    "Column 600 - Predicted stance (categorical)\n",
    "\n",
    "Column 601 - Claim veracity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "claim_columns = []\n",
    "for index in range(300):\n",
    "    claim_columns.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "previous_vector2 = \"\"\n",
    "previous_claim2 = \"\"\n",
    "for claim in my_claims['claim']:\n",
    "    vector = calc_vector(claim, previous_claim2, previous_vector2)\n",
    "    for index in range(300):\n",
    "        if vector==[]:\n",
    "            claim_columns[index].append(\"\")\n",
    "        else:\n",
    "            claim_columns[index].append(vector[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell takes the word embedding for each vector and puts in its own column. For example - claim_columns[0] has the first element of each claim's word embedding. claim_columns[1] has the second element, claim_columns[299] has the last element of each claim's word embedding.\n",
    "\n",
    "These will be the first 300 columns of my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_columns = []\n",
    "for index in range(300):\n",
    "    article_columns.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_vector2 = \"\"\n",
    "previous_claim2 = \"\"\n",
    "for article in my_claims['articleHeadline']:\n",
    "    vector = calc_vector(article, previous_claim2, previous_vector2)\n",
    "    for index in range(300):\n",
    "        if vector==[]:\n",
    "            article_columns[index].append(\"\")\n",
    "        else:\n",
    "            article_columns[index].append(vector[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "#transferring claim_columns to this dataframe\n",
    "for index in range(300):\n",
    "    final_df['claim'+str(index)] = claim_columns[index]\n",
    "    \n",
    "#transferring article_columns\n",
    "for index in range(300):\n",
    "    final_df['article'+str(index)] = article_columns[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.fillna(final_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim0</th>\n",
       "      <th>claim1</th>\n",
       "      <th>claim2</th>\n",
       "      <th>claim3</th>\n",
       "      <th>claim4</th>\n",
       "      <th>claim5</th>\n",
       "      <th>claim6</th>\n",
       "      <th>claim7</th>\n",
       "      <th>claim8</th>\n",
       "      <th>claim9</th>\n",
       "      <th>...</th>\n",
       "      <th>article290</th>\n",
       "      <th>article291</th>\n",
       "      <th>article292</th>\n",
       "      <th>article293</th>\n",
       "      <th>article294</th>\n",
       "      <th>article295</th>\n",
       "      <th>article296</th>\n",
       "      <th>article297</th>\n",
       "      <th>article298</th>\n",
       "      <th>article299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.00793457</td>\n",
       "      <td>-0.558594</td>\n",
       "      <td>-0.162109</td>\n",
       "      <td>0.416016</td>\n",
       "      <td>-0.057373</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>-0.0437012</td>\n",
       "      <td>-0.213867</td>\n",
       "      <td>0.0157471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0126343</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.00674438</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>-0.240234</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>-0.0727539</td>\n",
       "      <td>-0.0157471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>-0.722656</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>-0.341797</td>\n",
       "      <td>-0.228516</td>\n",
       "      <td>0.0927734</td>\n",
       "      <td>-0.108887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0605469</td>\n",
       "      <td>-0.185547</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>0.0280762</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>-0.209961</td>\n",
       "      <td>0.0786133</td>\n",
       "      <td>0.0966797</td>\n",
       "      <td>-0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>-0.0230713</td>\n",
       "      <td>-0.361328</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.306641</td>\n",
       "      <td>-0.126953</td>\n",
       "      <td>-0.0202637</td>\n",
       "      <td>-0.135742</td>\n",
       "      <td>-0.0456543</td>\n",
       "      <td>0.0678711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>0.0480957</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>0.0683594</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>0.232422</td>\n",
       "      <td>0.0241699</td>\n",
       "      <td>-0.0600586</td>\n",
       "      <td>0.306641</td>\n",
       "      <td>-0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>-0.228516</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.0167236</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>-0.15625</td>\n",
       "      <td>-0.196289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0639648</td>\n",
       "      <td>-0.0644531</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>0.103027</td>\n",
       "      <td>-0.0424805</td>\n",
       "      <td>0.166992</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>-0.00262451</td>\n",
       "      <td>-0.130859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.0673828</td>\n",
       "      <td>-0.239258</td>\n",
       "      <td>-0.0947266</td>\n",
       "      <td>0.22168</td>\n",
       "      <td>-0.104004</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>-0.0527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090332</td>\n",
       "      <td>-0.21582</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.0203857</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>-0.169922</td>\n",
       "      <td>-0.10498</td>\n",
       "      <td>-0.0206299</td>\n",
       "      <td>-0.0114136</td>\n",
       "      <td>-0.017334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.0654297</td>\n",
       "      <td>-0.0272217</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.291016</td>\n",
       "      <td>0.12207</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232422</td>\n",
       "      <td>0.0593262</td>\n",
       "      <td>-0.185547</td>\n",
       "      <td>0.0927734</td>\n",
       "      <td>-0.180664</td>\n",
       "      <td>0.00312805</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>-0.0678711</td>\n",
       "      <td>0.0247803</td>\n",
       "      <td>-0.120117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.0654297</td>\n",
       "      <td>-0.0272217</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.291016</td>\n",
       "      <td>0.12207</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.106934</td>\n",
       "      <td>0.12793</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>-0.0869141</td>\n",
       "      <td>-0.0148315</td>\n",
       "      <td>0.0698242</td>\n",
       "      <td>-0.0849609</td>\n",
       "      <td>-0.155273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.0654297</td>\n",
       "      <td>-0.0272217</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.291016</td>\n",
       "      <td>0.12207</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0761719</td>\n",
       "      <td>-0.220703</td>\n",
       "      <td>-0.423828</td>\n",
       "      <td>-0.0732422</td>\n",
       "      <td>-0.134766</td>\n",
       "      <td>0.0766602</td>\n",
       "      <td>0.0859375</td>\n",
       "      <td>-0.0595703</td>\n",
       "      <td>-0.180664</td>\n",
       "      <td>-0.181641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.0654297</td>\n",
       "      <td>-0.0272217</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.291016</td>\n",
       "      <td>0.12207</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.149414</td>\n",
       "      <td>0.0654297</td>\n",
       "      <td>-0.0272217</td>\n",
       "      <td>-0.129883</td>\n",
       "      <td>0.230469</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.291016</td>\n",
       "      <td>0.12207</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123047</td>\n",
       "      <td>0.0230713</td>\n",
       "      <td>-0.185547</td>\n",
       "      <td>-0.0213623</td>\n",
       "      <td>0.00239563</td>\n",
       "      <td>-0.000495911</td>\n",
       "      <td>0.0192871</td>\n",
       "      <td>-0.0717773</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>0.125977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      claim0     claim1     claim2    claim3     claim4    claim5    claim6  \\\n",
       "0  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "1  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "2  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "3  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "4  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "5  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "6  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "7  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "8  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "9  -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "10  0.149414  0.0654297 -0.0272217 -0.129883   0.230469 -0.152344     -0.25   \n",
       "11  0.149414  0.0654297 -0.0272217 -0.129883   0.230469 -0.152344     -0.25   \n",
       "12  0.149414  0.0654297 -0.0272217 -0.129883   0.230469 -0.152344     -0.25   \n",
       "13  0.149414  0.0654297 -0.0272217 -0.129883   0.230469 -0.152344     -0.25   \n",
       "14  0.149414  0.0654297 -0.0272217 -0.129883   0.230469 -0.152344     -0.25   \n",
       "\n",
       "       claim7     claim8     claim9    ...     article290  article291  \\\n",
       "0   0.0703125 -0.0712891 -0.0966797    ...       0.322266  0.00793457   \n",
       "1   0.0703125 -0.0712891 -0.0966797    ...      0.0126343   -0.115234   \n",
       "2   0.0703125 -0.0712891 -0.0966797    ...       0.139648   -0.147461   \n",
       "3   0.0703125 -0.0712891 -0.0966797    ...      0.0605469   -0.185547   \n",
       "4   0.0703125 -0.0712891 -0.0966797    ...       0.139648  -0.0230713   \n",
       "5   0.0703125 -0.0712891 -0.0966797    ...      -0.183594   0.0480957   \n",
       "6   0.0703125 -0.0712891 -0.0966797    ...       0.273438    0.108887   \n",
       "7   0.0703125 -0.0712891 -0.0966797    ...      0.0639648  -0.0644531   \n",
       "8   0.0703125 -0.0712891 -0.0966797    ...      -0.137695   0.0673828   \n",
       "9   0.0703125 -0.0712891 -0.0966797    ...       0.090332    -0.21582   \n",
       "10  -0.291016    0.12207   0.337891    ...      -0.232422   0.0593262   \n",
       "11  -0.291016    0.12207   0.337891    ...      -0.183594   -0.148438   \n",
       "12  -0.291016    0.12207   0.337891    ...     -0.0761719   -0.220703   \n",
       "13  -0.291016    0.12207   0.337891    ...                              \n",
       "14  -0.291016    0.12207   0.337891    ...       0.123047   0.0230713   \n",
       "\n",
       "   article292  article293  article294   article295 article296 article297  \\\n",
       "0   -0.558594   -0.162109    0.416016    -0.057373  -0.117676 -0.0437012   \n",
       "1      -0.125  0.00674438    0.148438    -0.240234   0.050293   0.121582   \n",
       "2   -0.722656    0.349609    0.097168     0.257812  -0.341797  -0.228516   \n",
       "3   -0.115234   0.0280762    0.106445    -0.265625  -0.209961  0.0786133   \n",
       "4   -0.361328    0.273438    0.306641    -0.126953 -0.0202637  -0.135742   \n",
       "5   -0.308594   0.0683594    0.170898     0.232422  0.0241699 -0.0600586   \n",
       "6   -0.228516   -0.140625  -0.0167236        -0.25   0.632812  -0.117188   \n",
       "7   -0.112305    0.108398    0.103027   -0.0424805   0.166992   0.131836   \n",
       "8   -0.239258  -0.0947266     0.22168    -0.104004   0.211914  -0.116211   \n",
       "9   -0.132812  -0.0203857    0.162109    -0.169922   -0.10498 -0.0206299   \n",
       "10  -0.185547   0.0927734   -0.180664   0.00312805   0.115234 -0.0678711   \n",
       "11  -0.106934     0.12793    0.546875   -0.0869141 -0.0148315  0.0698242   \n",
       "12  -0.423828  -0.0732422   -0.134766    0.0766602  0.0859375 -0.0595703   \n",
       "13                                                                         \n",
       "14  -0.185547  -0.0213623  0.00239563 -0.000495911  0.0192871 -0.0717773   \n",
       "\n",
       "    article298 article299  \n",
       "0    -0.213867  0.0157471  \n",
       "1   -0.0727539 -0.0157471  \n",
       "2    0.0927734  -0.108887  \n",
       "3    0.0966797     -0.125  \n",
       "4   -0.0456543  0.0678711  \n",
       "5     0.306641   -0.28125  \n",
       "6     -0.15625  -0.196289  \n",
       "7  -0.00262451  -0.130859  \n",
       "8     0.115723 -0.0527344  \n",
       "9   -0.0114136  -0.017334  \n",
       "10   0.0247803  -0.120117  \n",
       "11  -0.0849609  -0.155273  \n",
       "12   -0.180664  -0.181641  \n",
       "13                         \n",
       "14   -0.117676   0.125977  \n",
       "\n",
       "[15 rows x 600 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_stance = my_claims['predictedStance']\n",
    "le = LabelEncoder()\n",
    "predicted_stances = le.fit_transform(predicted_stance)\n",
    "\n",
    "#against = 0, for = 1, observing = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stances[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim0</th>\n",
       "      <th>claim1</th>\n",
       "      <th>claim2</th>\n",
       "      <th>claim3</th>\n",
       "      <th>claim4</th>\n",
       "      <th>claim5</th>\n",
       "      <th>claim6</th>\n",
       "      <th>claim7</th>\n",
       "      <th>claim8</th>\n",
       "      <th>claim9</th>\n",
       "      <th>...</th>\n",
       "      <th>article291</th>\n",
       "      <th>article292</th>\n",
       "      <th>article293</th>\n",
       "      <th>article294</th>\n",
       "      <th>article295</th>\n",
       "      <th>article296</th>\n",
       "      <th>article297</th>\n",
       "      <th>article298</th>\n",
       "      <th>article299</th>\n",
       "      <th>predictedStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00793457</td>\n",
       "      <td>-0.558594</td>\n",
       "      <td>-0.162109</td>\n",
       "      <td>0.416016</td>\n",
       "      <td>-0.057373</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>-0.0437012</td>\n",
       "      <td>-0.213867</td>\n",
       "      <td>0.0157471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.00674438</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>-0.240234</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>0.121582</td>\n",
       "      <td>-0.0727539</td>\n",
       "      <td>-0.0157471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147461</td>\n",
       "      <td>-0.722656</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>-0.341797</td>\n",
       "      <td>-0.228516</td>\n",
       "      <td>0.0927734</td>\n",
       "      <td>-0.108887</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185547</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>0.0280762</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>-0.209961</td>\n",
       "      <td>0.0786133</td>\n",
       "      <td>0.0966797</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.125977</td>\n",
       "      <td>-0.0322266</td>\n",
       "      <td>-0.0568848</td>\n",
       "      <td>0.220703</td>\n",
       "      <td>-0.0192871</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>-0.112305</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>-0.0712891</td>\n",
       "      <td>-0.0966797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0230713</td>\n",
       "      <td>-0.361328</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.306641</td>\n",
       "      <td>-0.126953</td>\n",
       "      <td>-0.0202637</td>\n",
       "      <td>-0.135742</td>\n",
       "      <td>-0.0456543</td>\n",
       "      <td>0.0678711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     claim0     claim1     claim2    claim3     claim4    claim5    claim6  \\\n",
       "0 -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "1 -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "2 -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "3 -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "4 -0.125977 -0.0322266 -0.0568848  0.220703 -0.0192871  0.427734 -0.112305   \n",
       "\n",
       "      claim7     claim8     claim9       ...        article291 article292  \\\n",
       "0  0.0703125 -0.0712891 -0.0966797       ...        0.00793457  -0.558594   \n",
       "1  0.0703125 -0.0712891 -0.0966797       ...         -0.115234     -0.125   \n",
       "2  0.0703125 -0.0712891 -0.0966797       ...         -0.147461  -0.722656   \n",
       "3  0.0703125 -0.0712891 -0.0966797       ...         -0.185547  -0.115234   \n",
       "4  0.0703125 -0.0712891 -0.0966797       ...        -0.0230713  -0.361328   \n",
       "\n",
       "   article293 article294 article295 article296 article297 article298  \\\n",
       "0   -0.162109   0.416016  -0.057373  -0.117676 -0.0437012  -0.213867   \n",
       "1  0.00674438   0.148438  -0.240234   0.050293   0.121582 -0.0727539   \n",
       "2    0.349609   0.097168   0.257812  -0.341797  -0.228516  0.0927734   \n",
       "3   0.0280762   0.106445  -0.265625  -0.209961  0.0786133  0.0966797   \n",
       "4    0.273438   0.306641  -0.126953 -0.0202637  -0.135742 -0.0456543   \n",
       "\n",
       "  article299 predictedStance  \n",
       "0  0.0157471               1  \n",
       "1 -0.0157471               0  \n",
       "2  -0.108887               2  \n",
       "3     -0.125               0  \n",
       "4  0.0678711               1  \n",
       "\n",
       "[5 rows x 601 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['predictedStance'] = predicted_stances\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46772, 601)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the only thing left is to bring in the claim veracities from the Snopes JSON files.\n",
    "\n",
    "My plan - \n",
    "\n",
    "1. First open my_claims_csv_cleaned.csv (because this has all the claims-article pairs) and then read the veracities into here. I will create a new column for this. I will save this as a new CSV (claims_with_veracities.csv)\n",
    "\n",
    "2. The problem now is that Snopes_articles_with_predicted_stance.csv has about 100 fewer articles in it (some claims have more than 10 articles associated with it). So for each claim which is present in Snopes_articles_with_predicted_stance.csv, I will search for that claim in claims_with_veracities.csv and then read off the corresponding veracity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_claims2 = pd.read_csv('my_claims_csv_cleaned.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veracity_dict = {}\n",
    "claims_file = glob.glob('Snopes\\*.json')\n",
    "index = 1\n",
    "for l in claims_file:\n",
    "    item = json.loads(open(l).read())\n",
    "    veracity_dict[index] = item['Credibility']\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_veracity(row):\n",
    "    index = row['claimId']\n",
    "    return veracity_dict[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_claims2['veracity'] = my_claims2.apply (lambda row: label_veracity (row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#There are four types of veracities - True, False, Mostly True, Mostly False\n",
    "\n",
    "#Number of instances of each - True: 12450, False:33177, Mostly True:279, Mostly False: 914\n",
    "\n",
    "#Because Mostly True and Mostly False are not that common, I am going to combine them into True and False. That is, I will \n",
    "#change Mostly True into True and Mostly False into False.\n",
    "\n",
    "new_column = []\n",
    "for v in my_claims2['veracity']:\n",
    "    if v==\"mostly false\":\n",
    "        new_column.append(\"False\")\n",
    "    elif v==\"mostly true\":\n",
    "        new_column.append(\"True\")\n",
    "    else:\n",
    "        new_column.append(v)\n",
    "        \n",
    "my_claims2['veracity'] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimHeadline</th>\n",
       "      <th>veracity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       claimHeadline veracity\n",
       "0  Meijer is offering 100 off Back to School coup...    false\n",
       "1  Meijer is offering 100 off Back to School coup...    false\n",
       "2  Meijer is offering 100 off Back to School coup...    false\n",
       "3  Meijer is offering 100 off Back to School coup...    false\n",
       "4  Meijer is offering 100 off Back to School coup...    false"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_csv = my_claims2[['claimHeadline', 'veracity']]\n",
    "relevant_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I just need to do step 2 - map the claims from relevant_csv to Snopes_articles_with_predicted_stance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
