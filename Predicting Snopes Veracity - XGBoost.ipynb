{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import pre-trained Word Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_model = gensim.models.KeyedVectors.load_word2vec_format('../../Downloads/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_model['nasa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the list of words for which the google model has a vector\n",
    "google_vocab = google_model.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Find Word Embeddings\n",
    "\n",
    "### 2.1- Embeddings of Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>articleHeadline</th>\n",
       "      <th>predictedStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 Meijer Coupon - Snopes.com</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>Fake Meijer 100 back-to-school coupon goes vir...</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 Meijer Coupon - Hoax - Trendolizer</td>\n",
       "      <td>observing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 OFF Meijer Coupon Deals April 2017 HotDeal...</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>10 off 100 in Visa Gift Cards at Meijer - Freq...</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Meijer is offering 100 off Back to School coup...   \n",
       "1  Meijer is offering 100 off Back to School coup...   \n",
       "2  Meijer is offering 100 off Back to School coup...   \n",
       "3  Meijer is offering 100 off Back to School coup...   \n",
       "4  Meijer is offering 100 off Back to School coup...   \n",
       "\n",
       "                                     articleHeadline predictedStance  \n",
       "0                     100 Meijer Coupon - Snopes.com             for  \n",
       "1  Fake Meijer 100 back-to-school coupon goes vir...         against  \n",
       "2             100 Meijer Coupon - Hoax - Trendolizer       observing  \n",
       "3  100 OFF Meijer Coupon Deals April 2017 HotDeal...         against  \n",
       "4  10 off 100 in Visa Gift Cards at Meijer - Freq...             for  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_claims = pd.read_csv('Snopes_articles_with_predicted_stance.csv', index_col = 0)\n",
    "my_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes in a string. Tokenizes it, removes any punctuation in it\n",
    "#Does NOT change the case of the words though.\n",
    "def preprocessing(text):\n",
    "    if pd.isnull(text): #if article doesn't exist. Some claims have <10 articles.\n",
    "        return \"\"\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c,\"\")\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For a claim or an articleHeadline, this function will return the word embedding for it\n",
    "def calc_vector(current_text, previous_text, previous_vector):\n",
    "    \n",
    "    #if article doesn't exist. Some claims have <10 articles\n",
    "    if pd.isnull(current_text):\n",
    "        return []\n",
    "    \n",
    "    #as each claim is repeated many times, this will be efficient for the 2nd through 10th time that we are finding the vector \n",
    "    #for a particular claim\n",
    "    if current_text==previous_text:\n",
    "        return previous_vector\n",
    "    \n",
    "    #if this is the first time we are finding the vector for this claim\n",
    "    words = preprocessing(current_text)\n",
    "    \n",
    "    text_vec = []\n",
    "    for word in words:\n",
    "        #checking if the word as written is in google model\n",
    "        if word in google_vocab:\n",
    "            text_vec =+ google_model[word]\n",
    "        \n",
    "        #checking if word in lowercase is in google model\n",
    "        elif word.lower() in google_vocab:\n",
    "            text_vec =+ google_model[word.lower()]\n",
    "        \n",
    "        #checking if word in uppercase is in google model\n",
    "        elif word.upper() in google_vocab:\n",
    "            text_vec =+ google_model[word.upper()]\n",
    "        \n",
    "        #checking if word in capital case (first character capitalized) is in model\n",
    "        elif word.capitalize() in google_vocab:\n",
    "            text_vec =+ google_model[word.capitalize()]\n",
    "        \n",
    "        #if not, just leave text_vec unchanged\n",
    "        else:\n",
    "            text_vec = text_vec\n",
    "    \n",
    "    #updating previous text and previous vector\n",
    "    previous_text = current_text\n",
    "    previous_vector = text_vec\n",
    "    \n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claim_word_embeddings = [] #This will be the first column in the new dataframe. 'claimWordEmbedding'\n",
    "previous_claim = ''\n",
    "previous_vector =[]\n",
    "for claim in my_claims['claim']:\n",
    "    claim_word_embeddings.append(calc_vector(claim, previous_claim, previous_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46772"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claim_word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_claims = []\n",
    "length = len(claim_word_embeddings)\n",
    "for index in range(0, length, 10):\n",
    "    unique_claims.append(claim_word_embeddings[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4678"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have the word embeddings for the claims. Now I have to get the word embeddings for the articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 Word Embeddings of Article Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>articleHeadline</th>\n",
       "      <th>predictedStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 Meijer Coupon - Snopes.com</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>Fake Meijer 100 back-to-school coupon goes vir...</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 Meijer Coupon - Hoax - Trendolizer</td>\n",
       "      <td>observing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>100 OFF Meijer Coupon Deals April 2017 HotDeal...</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>10 off 100 in Visa Gift Cards at Meijer - Freq...</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Meijer is offering 100 off Back to School coup...   \n",
       "1  Meijer is offering 100 off Back to School coup...   \n",
       "2  Meijer is offering 100 off Back to School coup...   \n",
       "3  Meijer is offering 100 off Back to School coup...   \n",
       "4  Meijer is offering 100 off Back to School coup...   \n",
       "\n",
       "                                     articleHeadline predictedStance  \n",
       "0                     100 Meijer Coupon - Snopes.com             for  \n",
       "1  Fake Meijer 100 back-to-school coupon goes vir...         against  \n",
       "2             100 Meijer Coupon - Hoax - Trendolizer       observing  \n",
       "3  100 OFF Meijer Coupon Deals April 2017 HotDeal...         against  \n",
       "4  10 off 100 in Visa Gift Cards at Meijer - Freq...             for  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Snopes_articles_with_predicted_stance.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#claim_embeddings is a list of numpy arrays. This should be a list of lists of numpy arrays\n",
    "article_embeddings = []\n",
    "articles = df['articleHeadline']\n",
    "multiples = math.floor(df.shape[0]/10)\n",
    "\n",
    "previous_claim2 = \"\"\n",
    "previous_vector2 = []\n",
    "\n",
    "for i in range(10):\n",
    "    article_embeddings.append([])\n",
    "    \n",
    "for i in range(df.shape[0]):\n",
    "    current = calc_vector(articles[i], previous_claim2, previous_vector2)\n",
    "    article_embeddings[i%10].append(current)\n",
    "#         article_embeddings[i].append(calc_vector(articles[i + num*10], previous_claim2, previous_vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4678\n",
      "4678\n",
      "4677\n",
      "4677\n",
      "4677\n",
      "4677\n",
      "4677\n",
      "4677\n",
      "4677\n",
      "4677\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(article_embeddings[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, article_embeddings is a list. Each element of article_embeddings[5], for example, is the fifth article for every claim. Currently, because the number of articles is not a multiple of 10, the lists are not of equal size. So I will add dummy vectors to make them even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n",
      "4678\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 10):\n",
    "    article_embeddings[i].append([])\n",
    "    \n",
    "for i in range(10):\n",
    "    print(len(article_embeddings[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they are even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I have all the word embeddings I need. I will try building an XGBoost model just with the word embeddings and see if it is respectable. Otherwise, I will create the following binary features for every article - \n",
    "\n",
    "    - whether it contains a hedging word\n",
    "    - whether it contains a question mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['claimEmbedding'] = unique_claims\n",
    "for index in range(10):\n",
    "    text = 'article' + str(index)\n",
    "    final_df[text] = article_embeddings[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimEmbedding</th>\n",
       "      <th>article0</th>\n",
       "      <th>article1</th>\n",
       "      <th>article2</th>\n",
       "      <th>article3</th>\n",
       "      <th>article4</th>\n",
       "      <th>article5</th>\n",
       "      <th>article6</th>\n",
       "      <th>article7</th>\n",
       "      <th>article8</th>\n",
       "      <th>article9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.125977, -0.0322266, -0.0568848, 0.220703, ...</td>\n",
       "      <td>[0.097168, 0.196289, -0.146484, 0.0849609, 0.1...</td>\n",
       "      <td>[0.0976563, -0.00927734, -0.267578, -0.28125, ...</td>\n",
       "      <td>[0.355469, 0.0201416, -0.065918, -0.0722656, 0...</td>\n",
       "      <td>[0.0888672, 0.00328064, 0.026001, -0.141602, -...</td>\n",
       "      <td>[0.065918, 0.0922852, -0.0952148, 0.0839844, 0...</td>\n",
       "      <td>[0.0556641, 0.378906, -0.179688, 0.330078, 0.0...</td>\n",
       "      <td>[0.251953, -0.191406, -0.121582, -0.00708008, ...</td>\n",
       "      <td>[0.0727539, -0.0927734, -0.174805, -0.022583, ...</td>\n",
       "      <td>[-0.00695801, 0.106445, -0.00830078, -0.023071...</td>\n",
       "      <td>[-0.0703125, -0.151367, -0.0932617, 0.0561523,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.149414, 0.0654297, -0.0272217, -0.129883, 0...</td>\n",
       "      <td>[0.115234, -0.0805664, -0.078125, 0.120605, -0...</td>\n",
       "      <td>[-0.125977, 0.0253906, 0.166992, 0.550781, -0....</td>\n",
       "      <td>[-0.201172, -0.0349121, -0.0742188, 0.0581055,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.101563, -0.267578, -0.0922852, 0.182617, -0...</td>\n",
       "      <td>[0.0456543, -0.157227, 0.0820313, 0.171875, 0....</td>\n",
       "      <td>[0.0456543, -0.157227, 0.0820313, 0.171875, 0....</td>\n",
       "      <td>[0.0380859, 0.291016, 0.0522461, 0.269531, -0....</td>\n",
       "      <td>[0.00595093, 0.310547, 0.0605469, 0.12793, -0....</td>\n",
       "      <td>[-0.151367, -0.283203, 0.402344, -0.0976563, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.078125, -0.0390625, -0.0766602, 0.416016, -...</td>\n",
       "      <td>[0.19043, -0.425781, -0.550781, 0.164063, -0.5...</td>\n",
       "      <td>[0.117676, 0.0532227, -0.324219, 0.0771484, 0....</td>\n",
       "      <td>[-0.090332, 0.0600586, -0.240234, 0.193359, -0...</td>\n",
       "      <td>[0.251953, -0.191406, -0.121582, -0.00708008, ...</td>\n",
       "      <td>[0.078125, -0.0390625, -0.0766602, 0.416016, -...</td>\n",
       "      <td>[-0.135742, 0.141602, -0.00756836, 0.143555, 0...</td>\n",
       "      <td>[-0.135742, 0.141602, -0.00756836, 0.143555, 0...</td>\n",
       "      <td>[0.00823975, -0.236328, 0.234375, -0.223633, -...</td>\n",
       "      <td>[-0.161133, 0.0786133, 0.0913086, -0.363281, -...</td>\n",
       "      <td>[0.0947266, 0.328125, -0.048584, -0.00665283, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.111816, 0.189453, 0.176758, -0.022583, 0.18...</td>\n",
       "      <td>[0.0351563, 0.208008, -0.417969, -0.165039, -0...</td>\n",
       "      <td>[0.111816, 0.189453, 0.176758, -0.022583, 0.18...</td>\n",
       "      <td>[-0.237305, -0.380859, -0.148438, 0.106445, 0....</td>\n",
       "      <td>[-0.0708008, -0.0664063, 0.0240479, -0.0500488...</td>\n",
       "      <td>[0.251953, -0.191406, -0.121582, -0.00708008, ...</td>\n",
       "      <td>[0.515625, 0.162109, -0.0263672, -0.0578613, -...</td>\n",
       "      <td>[-0.0610352, -0.314453, 0.150391, -0.0595703, ...</td>\n",
       "      <td>[-0.0610352, -0.314453, 0.150391, -0.0595703, ...</td>\n",
       "      <td>[-0.00958252, 0.371094, 0.0639648, 0.0922852, ...</td>\n",
       "      <td>[-0.0456543, 0.0908203, 0.0446777, 0.365234, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0810547, -0.0400391, 0.050293, -0.157227, -...</td>\n",
       "      <td>[0.0429688, -0.0130615, 0.0703125, -0.161133, ...</td>\n",
       "      <td>[0.0810547, -0.0400391, 0.050293, -0.157227, -...</td>\n",
       "      <td>[0.0810547, -0.0400391, 0.050293, -0.157227, -...</td>\n",
       "      <td>[-0.24707, 0.00927734, 0.00787354, 0.176758, -...</td>\n",
       "      <td>[-0.0981445, -0.324219, -0.412109, -0.0517578,...</td>\n",
       "      <td>[0.121094, 0.145508, 0.145508, -0.206055, 0.04...</td>\n",
       "      <td>[0.0284424, -0.036377, -0.225586, 0.0322266, 0...</td>\n",
       "      <td>[0.0267334, -0.0908203, 0.027832, 0.204102, 0....</td>\n",
       "      <td>[0.0263672, 0.0300293, 0.032959, 0.245117, 0.1...</td>\n",
       "      <td>[-0.0334473, 0.0253906, -0.300781, 0.0356445, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      claimEmbedding  \\\n",
       "0  [-0.125977, -0.0322266, -0.0568848, 0.220703, ...   \n",
       "1  [0.149414, 0.0654297, -0.0272217, -0.129883, 0...   \n",
       "2  [0.078125, -0.0390625, -0.0766602, 0.416016, -...   \n",
       "3  [0.111816, 0.189453, 0.176758, -0.022583, 0.18...   \n",
       "4  [0.0810547, -0.0400391, 0.050293, -0.157227, -...   \n",
       "\n",
       "                                            article0  \\\n",
       "0  [0.097168, 0.196289, -0.146484, 0.0849609, 0.1...   \n",
       "1  [0.115234, -0.0805664, -0.078125, 0.120605, -0...   \n",
       "2  [0.19043, -0.425781, -0.550781, 0.164063, -0.5...   \n",
       "3  [0.0351563, 0.208008, -0.417969, -0.165039, -0...   \n",
       "4  [0.0429688, -0.0130615, 0.0703125, -0.161133, ...   \n",
       "\n",
       "                                            article1  \\\n",
       "0  [0.0976563, -0.00927734, -0.267578, -0.28125, ...   \n",
       "1  [-0.125977, 0.0253906, 0.166992, 0.550781, -0....   \n",
       "2  [0.117676, 0.0532227, -0.324219, 0.0771484, 0....   \n",
       "3  [0.111816, 0.189453, 0.176758, -0.022583, 0.18...   \n",
       "4  [0.0810547, -0.0400391, 0.050293, -0.157227, -...   \n",
       "\n",
       "                                            article2  \\\n",
       "0  [0.355469, 0.0201416, -0.065918, -0.0722656, 0...   \n",
       "1  [-0.201172, -0.0349121, -0.0742188, 0.0581055,...   \n",
       "2  [-0.090332, 0.0600586, -0.240234, 0.193359, -0...   \n",
       "3  [-0.237305, -0.380859, -0.148438, 0.106445, 0....   \n",
       "4  [0.0810547, -0.0400391, 0.050293, -0.157227, -...   \n",
       "\n",
       "                                            article3  \\\n",
       "0  [0.0888672, 0.00328064, 0.026001, -0.141602, -...   \n",
       "1                                                 []   \n",
       "2  [0.251953, -0.191406, -0.121582, -0.00708008, ...   \n",
       "3  [-0.0708008, -0.0664063, 0.0240479, -0.0500488...   \n",
       "4  [-0.24707, 0.00927734, 0.00787354, 0.176758, -...   \n",
       "\n",
       "                                            article4  \\\n",
       "0  [0.065918, 0.0922852, -0.0952148, 0.0839844, 0...   \n",
       "1  [0.101563, -0.267578, -0.0922852, 0.182617, -0...   \n",
       "2  [0.078125, -0.0390625, -0.0766602, 0.416016, -...   \n",
       "3  [0.251953, -0.191406, -0.121582, -0.00708008, ...   \n",
       "4  [-0.0981445, -0.324219, -0.412109, -0.0517578,...   \n",
       "\n",
       "                                            article5  \\\n",
       "0  [0.0556641, 0.378906, -0.179688, 0.330078, 0.0...   \n",
       "1  [0.0456543, -0.157227, 0.0820313, 0.171875, 0....   \n",
       "2  [-0.135742, 0.141602, -0.00756836, 0.143555, 0...   \n",
       "3  [0.515625, 0.162109, -0.0263672, -0.0578613, -...   \n",
       "4  [0.121094, 0.145508, 0.145508, -0.206055, 0.04...   \n",
       "\n",
       "                                            article6  \\\n",
       "0  [0.251953, -0.191406, -0.121582, -0.00708008, ...   \n",
       "1  [0.0456543, -0.157227, 0.0820313, 0.171875, 0....   \n",
       "2  [-0.135742, 0.141602, -0.00756836, 0.143555, 0...   \n",
       "3  [-0.0610352, -0.314453, 0.150391, -0.0595703, ...   \n",
       "4  [0.0284424, -0.036377, -0.225586, 0.0322266, 0...   \n",
       "\n",
       "                                            article7  \\\n",
       "0  [0.0727539, -0.0927734, -0.174805, -0.022583, ...   \n",
       "1  [0.0380859, 0.291016, 0.0522461, 0.269531, -0....   \n",
       "2  [0.00823975, -0.236328, 0.234375, -0.223633, -...   \n",
       "3  [-0.0610352, -0.314453, 0.150391, -0.0595703, ...   \n",
       "4  [0.0267334, -0.0908203, 0.027832, 0.204102, 0....   \n",
       "\n",
       "                                            article8  \\\n",
       "0  [-0.00695801, 0.106445, -0.00830078, -0.023071...   \n",
       "1  [0.00595093, 0.310547, 0.0605469, 0.12793, -0....   \n",
       "2  [-0.161133, 0.0786133, 0.0913086, -0.363281, -...   \n",
       "3  [-0.00958252, 0.371094, 0.0639648, 0.0922852, ...   \n",
       "4  [0.0263672, 0.0300293, 0.032959, 0.245117, 0.1...   \n",
       "\n",
       "                                            article9  \n",
       "0  [-0.0703125, -0.151367, -0.0932617, 0.0561523,...  \n",
       "1  [-0.151367, -0.283203, 0.402344, -0.0976563, 0...  \n",
       "2  [0.0947266, 0.328125, -0.048584, -0.00665283, ...  \n",
       "3  [-0.0456543, 0.0908203, 0.0446777, 0.365234, -...  \n",
       "4  [-0.0334473, 0.0253906, -0.300781, 0.0356445, ...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the veracity information (which I will read from the JSON files) this is ~85% of the dataframe I want. There are two problems now -\n",
    "\n",
    "1. There are some articles for which the google model has no words. So for those, the word embedding vector is just empty. I thought I fixed this problem but I can solve this by just going through and replacing them with the means of the columns.\n",
    "\n",
    "2. I had previously decided that for the claims with missing articles, I would just put those embeddings as a vector of zeros. On second thoughts, it might be a better idea to replace them with the means of the respective columns.\n",
    "\n",
    "I will first replace the zero vectors, and the empty ones because the zero vectors will affect the column mean, which I do not want\n",
    "\n",
    "EDIT: I am not sure how to remove the zero vectors. So I will just replace the empty ones with the column mean and see how that works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claimEmbedding</th>\n",
       "      <th>article0</th>\n",
       "      <th>article1</th>\n",
       "      <th>article2</th>\n",
       "      <th>article3</th>\n",
       "      <th>article4</th>\n",
       "      <th>article5</th>\n",
       "      <th>article6</th>\n",
       "      <th>article7</th>\n",
       "      <th>article8</th>\n",
       "      <th>article9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>[0.12793, 0.00341797, 0.195313, 0.283203, -0.0...</td>\n",
       "      <td>[-0.273438, -0.134766, -0.225586, 0.0644531, 0...</td>\n",
       "      <td>[-0.236328, -0.0249023, -0.169922, -0.185547, ...</td>\n",
       "      <td>[0.0834961, 0.0649414, 0.155273, 0.166016, 0.2...</td>\n",
       "      <td>[-0.236328, -0.0249023, -0.169922, -0.185547, ...</td>\n",
       "      <td>[0.3125, -0.289063, -0.177734, 0.302734, 0.146...</td>\n",
       "      <td>[0.423828, -0.00717163, 0.105469, -0.147461, -...</td>\n",
       "      <td>[0.125, -0.124023, -0.137695, 0.130859, -0.394...</td>\n",
       "      <td>[-0.0383301, 0.12207, 0.168945, 0.0239258, -0....</td>\n",
       "      <td>[-0.0673828, -0.0981445, 0.363281, 0.10791, 0....</td>\n",
       "      <td>[-0.236328, -0.0249023, -0.169922, -0.185547, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>[-0.0446777, 0.0571289, 0.328125, 0.0629883, 0...</td>\n",
       "      <td>[0.220703, -0.0703125, -0.246094, -0.273438, -...</td>\n",
       "      <td>[-0.0922852, 0.203125, -0.186523, 0.15918, -0....</td>\n",
       "      <td>[0.0537109, 0.15625, -0.192383, 0.146484, -0.0...</td>\n",
       "      <td>[-0.0644531, 0.182617, 0.0639648, 0.0625, -0.0...</td>\n",
       "      <td>[-0.236328, -0.0249023, -0.169922, -0.185547, ...</td>\n",
       "      <td>[-0.0175781, 0.224609, -0.0683594, 0.0673828, ...</td>\n",
       "      <td>[0.125977, -0.18457, -0.304688, 0.0568848, -0....</td>\n",
       "      <td>[0.124023, 0.28125, -0.0272217, -0.02771, -0.0...</td>\n",
       "      <td>[-0.324219, 0.163086, -0.255859, 0.0495605, -0...</td>\n",
       "      <td>[-0.414063, 0.0153198, -0.123535, 0.251953, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>[-0.0175781, 0.224609, -0.0683594, 0.0673828, ...</td>\n",
       "      <td>[0.172852, 0.283203, -0.28125, 0.417969, -0.07...</td>\n",
       "      <td>[0.0378418, 0.200195, 0.267578, 0.0088501, -0....</td>\n",
       "      <td>[0.0834961, 0.0649414, 0.155273, 0.166016, 0.2...</td>\n",
       "      <td>[-0.126953, 0.208984, -0.106445, 0.0471191, -0...</td>\n",
       "      <td>[0.109375, -0.0375977, -0.0693359, -0.149414, ...</td>\n",
       "      <td>[0.251953, -0.191406, -0.121582, -0.00708008, ...</td>\n",
       "      <td>[0.240234, 0.144531, -0.177734, -0.0297852, 0....</td>\n",
       "      <td>[0.00656128, 0.222656, -0.0292969, 0.179688, -...</td>\n",
       "      <td>[-0.105957, 0.213867, 0.118652, -0.0314941, -0...</td>\n",
       "      <td>[0.0529785, -0.0742188, -0.130859, 0.171875, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>[0.245117, -0.0177002, -0.0634766, 0.128906, 0...</td>\n",
       "      <td>[0.0529785, -0.0742188, -0.130859, 0.171875, 0...</td>\n",
       "      <td>[0.0529785, -0.0742188, -0.130859, 0.171875, 0...</td>\n",
       "      <td>[-0.105957, 0.213867, 0.118652, -0.0314941, -0...</td>\n",
       "      <td>[0.117676, 0.0532227, -0.324219, 0.0771484, 0....</td>\n",
       "      <td>[0.376953, 0.175781, 0.169922, 0.197266, -0.00...</td>\n",
       "      <td>[0.138672, 0.119141, -0.359375, 0.235352, -0.0...</td>\n",
       "      <td>[-0.201172, -0.198242, -0.244141, -0.0471191, ...</td>\n",
       "      <td>[-0.0510254, 0.120605, -0.0125732, 0.0308838, ...</td>\n",
       "      <td>[-0.0585938, -0.0375977, 0.0727539, 0.108887, ...</td>\n",
       "      <td>[-0.0498047, -0.328125, -0.0415039, 0.271484, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4677</th>\n",
       "      <td>[0.0568848, 0.0742188, 0.0432129, -0.106934, -...</td>\n",
       "      <td>[0.155273, -0.318359, -0.133789, 0.0766602, -0...</td>\n",
       "      <td>[-0.209961, -0.0354004, -0.158203, 0.00357056,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         claimEmbedding  \\\n",
       "4673  [0.12793, 0.00341797, 0.195313, 0.283203, -0.0...   \n",
       "4674  [-0.0446777, 0.0571289, 0.328125, 0.0629883, 0...   \n",
       "4675  [-0.0175781, 0.224609, -0.0683594, 0.0673828, ...   \n",
       "4676  [0.245117, -0.0177002, -0.0634766, 0.128906, 0...   \n",
       "4677  [0.0568848, 0.0742188, 0.0432129, -0.106934, -...   \n",
       "\n",
       "                                               article0  \\\n",
       "4673  [-0.273438, -0.134766, -0.225586, 0.0644531, 0...   \n",
       "4674  [0.220703, -0.0703125, -0.246094, -0.273438, -...   \n",
       "4675  [0.172852, 0.283203, -0.28125, 0.417969, -0.07...   \n",
       "4676  [0.0529785, -0.0742188, -0.130859, 0.171875, 0...   \n",
       "4677  [0.155273, -0.318359, -0.133789, 0.0766602, -0...   \n",
       "\n",
       "                                               article1  \\\n",
       "4673  [-0.236328, -0.0249023, -0.169922, -0.185547, ...   \n",
       "4674  [-0.0922852, 0.203125, -0.186523, 0.15918, -0....   \n",
       "4675  [0.0378418, 0.200195, 0.267578, 0.0088501, -0....   \n",
       "4676  [0.0529785, -0.0742188, -0.130859, 0.171875, 0...   \n",
       "4677  [-0.209961, -0.0354004, -0.158203, 0.00357056,...   \n",
       "\n",
       "                                               article2  \\\n",
       "4673  [0.0834961, 0.0649414, 0.155273, 0.166016, 0.2...   \n",
       "4674  [0.0537109, 0.15625, -0.192383, 0.146484, -0.0...   \n",
       "4675  [0.0834961, 0.0649414, 0.155273, 0.166016, 0.2...   \n",
       "4676  [-0.105957, 0.213867, 0.118652, -0.0314941, -0...   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article3  \\\n",
       "4673  [-0.236328, -0.0249023, -0.169922, -0.185547, ...   \n",
       "4674  [-0.0644531, 0.182617, 0.0639648, 0.0625, -0.0...   \n",
       "4675  [-0.126953, 0.208984, -0.106445, 0.0471191, -0...   \n",
       "4676  [0.117676, 0.0532227, -0.324219, 0.0771484, 0....   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article4  \\\n",
       "4673  [0.3125, -0.289063, -0.177734, 0.302734, 0.146...   \n",
       "4674  [-0.236328, -0.0249023, -0.169922, -0.185547, ...   \n",
       "4675  [0.109375, -0.0375977, -0.0693359, -0.149414, ...   \n",
       "4676  [0.376953, 0.175781, 0.169922, 0.197266, -0.00...   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article5  \\\n",
       "4673  [0.423828, -0.00717163, 0.105469, -0.147461, -...   \n",
       "4674  [-0.0175781, 0.224609, -0.0683594, 0.0673828, ...   \n",
       "4675  [0.251953, -0.191406, -0.121582, -0.00708008, ...   \n",
       "4676  [0.138672, 0.119141, -0.359375, 0.235352, -0.0...   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article6  \\\n",
       "4673  [0.125, -0.124023, -0.137695, 0.130859, -0.394...   \n",
       "4674  [0.125977, -0.18457, -0.304688, 0.0568848, -0....   \n",
       "4675  [0.240234, 0.144531, -0.177734, -0.0297852, 0....   \n",
       "4676  [-0.201172, -0.198242, -0.244141, -0.0471191, ...   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article7  \\\n",
       "4673  [-0.0383301, 0.12207, 0.168945, 0.0239258, -0....   \n",
       "4674  [0.124023, 0.28125, -0.0272217, -0.02771, -0.0...   \n",
       "4675  [0.00656128, 0.222656, -0.0292969, 0.179688, -...   \n",
       "4676  [-0.0510254, 0.120605, -0.0125732, 0.0308838, ...   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article8  \\\n",
       "4673  [-0.0673828, -0.0981445, 0.363281, 0.10791, 0....   \n",
       "4674  [-0.324219, 0.163086, -0.255859, 0.0495605, -0...   \n",
       "4675  [-0.105957, 0.213867, 0.118652, -0.0314941, -0...   \n",
       "4676  [-0.0585938, -0.0375977, 0.0727539, 0.108887, ...   \n",
       "4677                                                 []   \n",
       "\n",
       "                                               article9  \n",
       "4673  [-0.236328, -0.0249023, -0.169922, -0.185547, ...  \n",
       "4674  [-0.414063, 0.0153198, -0.123535, 0.251953, 0....  \n",
       "4675  [0.0529785, -0.0742188, -0.130859, 0.171875, 0...  \n",
       "4676  [-0.0498047, -0.328125, -0.0415039, 0.271484, ...  \n",
       "4677                                                 []  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = final_df.fillna(final_df.mean())\n",
    "final_df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
