{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya Kharosekar\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Import pre-trained Word Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_model = gensim.models.KeyedVectors.load_word2vec_format('../../Downloads/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "google_model['nasa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the list of words for which the google model has a vector\n",
    "google_vocab = google_model.vocab.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Find Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>claimId</th>\n",
       "      <th>claimTruthiness</th>\n",
       "      <th>claimHeadline</th>\n",
       "      <th>articleId</th>\n",
       "      <th>articleVersion</th>\n",
       "      <th>articleHeadline</th>\n",
       "      <th>articleHeadlineStance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100 Meijer Coupon - Snopes.com</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake Meijer 100 back-to-school coupon goes vir...</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100 Meijer Coupon - Hoax - Trendolizer</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100 OFF Meijer Coupon Deals April 2017 HotDeal...</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Meijer is offering 100 off Back to School coup...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10 off 100 in Visa Gift Cards at Meijer - Freq...</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  claimId claimTruthiness  \\\n",
       "0           0        1         unknown   \n",
       "1           1        1         unknown   \n",
       "2           2        1         unknown   \n",
       "3           3        1         unknown   \n",
       "4           4        1         unknown   \n",
       "\n",
       "                                       claimHeadline  articleId  \\\n",
       "0  Meijer is offering 100 off Back to School coup...          0   \n",
       "1  Meijer is offering 100 off Back to School coup...          1   \n",
       "2  Meijer is offering 100 off Back to School coup...          2   \n",
       "3  Meijer is offering 100 off Back to School coup...          3   \n",
       "4  Meijer is offering 100 off Back to School coup...          4   \n",
       "\n",
       "   articleVersion                                    articleHeadline  \\\n",
       "0               1                     100 Meijer Coupon - Snopes.com   \n",
       "1               1  Fake Meijer 100 back-to-school coupon goes vir...   \n",
       "2               1             100 Meijer Coupon - Hoax - Trendolizer   \n",
       "3               1  100 OFF Meijer Coupon Deals April 2017 HotDeal...   \n",
       "4               1  10 off 100 in Visa Gift Cards at Meijer - Freq...   \n",
       "\n",
       "  articleHeadlineStance  \n",
       "0                   for  \n",
       "1                   for  \n",
       "2                   for  \n",
       "3                   for  \n",
       "4                   for  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_claims = pd.read_csv('my_claims_csv_cleaned.csv', index_col = 1)\n",
    "my_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes in a string. Tokenizes it, removes any punctuation in it\n",
    "#Does NOT change the case of the words though.\n",
    "def preprocessing(text):\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c,\"\")\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For a claim or an articleHeadline, this function will return the word embedding for it\n",
    "def calc_vector(current_text, previous_text, previous_vector):\n",
    "    \n",
    "    #as each claim is repeated many times, this will be efficient for the 2nd through 10th time that we are finding the vector \n",
    "    #for a particular claim\n",
    "    if current_text==previous_text:\n",
    "        return previous_vector\n",
    "    \n",
    "    #if this is the first time we are finding the vector for this claim\n",
    "    words = preprocessing(current_text)\n",
    "    \n",
    "    text_vec = []\n",
    "    for word in words:\n",
    "        #checking if the word as written is in google model\n",
    "        if word in google_vocab:\n",
    "            text_vec =+ google_model[word]\n",
    "        \n",
    "        #checking if word in lowercase is in google model\n",
    "        elif word.lower() in google_vocab:\n",
    "            text_vec =+ google_model[word.lower()]\n",
    "        \n",
    "        #checking if word in uppercase is in google model\n",
    "        elif word.upper() in google_vocab:\n",
    "            text_vec =+ google_model[word.upper()]\n",
    "        \n",
    "        #checking if word in capital case (first character capitalized) is in model\n",
    "        elif word.capitalize() in google_vocab:\n",
    "            text_vec =+ google_model[word.capitalize()]\n",
    "        \n",
    "        #if not, just leave text_vec unchanged\n",
    "        else:\n",
    "            text_vec = text_vec\n",
    "    \n",
    "    #updating previous text and previous vector\n",
    "    previous_text = current_text\n",
    "    previous_vector = text_vec\n",
    "    \n",
    "    return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claim_word_embeddings = [] #This will be the first column in the new dataframe. 'claimWordEmbedding'\n",
    "previous_claim = ''\n",
    "previous_vector =[]\n",
    "for claim in my_claims['claimHeadline']:\n",
    "    claim_word_embeddings.append(calc_vector(claim, previous_claim, previous_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46820"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claim_word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have the word embeddings for the claims. Now I have to get the word embeddings for the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
